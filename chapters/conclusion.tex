\section{Conclusion}
In this paper, we introduced a combinations of Recursive Neural Network and Convolution Neural Network for sentence-level sentiment analysis.
We did experiments with both tree-structured and sequential Recursive Neural Networks.
Using Standford Sentiment Treebank, we demonstrated that Recurrent or Recursive Neural Networks can be used for combining phrase-level features produced by Convolution Neural Networks.
Our experiments show that these combinations outperform most original Convolution, Recurrent and Recursive Neural Networks. 
We think that the usage of Recurrent or Recursive Neural Networks is better than k-max-pooling layer in the respect of preserving features' position information and capturing long-range dependencies between features. 

Additionally, in attempt to improve vector presentations of words, we trained Glove vectors on the gigantic Amazon Reviews dataset (Glove Amazon).
We have demonstrated Glove Amazon is good for models on binary setting but can be harmful for them in fine-grained setting.
Our experiments also show that a combination of both Glove Amazon and the standard Glove is more beneficial for CNN-Tree-LSTM compared to CNN-LSTM as 2-channel CNN-Tree-LSTM is able to outperform 2-channel CNN-LSTM on both binary and fine-grained setting.

Given the success of Glove Amazon, we will pre-train Multichannel CNN-LSTM as a language model on Amazon Reviews dataset.

