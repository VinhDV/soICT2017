\section{Conclusion}
In this paper, we introduced a combination of Recursive Neural Network and Convolution Neural Network for sentence-level sentiment analysis.
We experimented with both tree-structured and sequential Recursive Neural Networks.
Using Standford Sentiment Treebank, we demonstrated that Recurrent or Recursive Neural Networks can be used for combining phrase-level features produced by Convolution Neural Networks.
Our experiments show that these combinations outperform most pure Convolution, Recurrent and Recursive Neural Networks.
These results provide further support for the hypothesis that the usage of Recurrent or Recursive Neural Networks is better than k-max-pooling layer in the respect of preserving features' position information and capturing long-range dependencies between features.

Additionally, in an attempt to improve vector presentations of words, we trained Glove vectors on the gigantic Amazon Reviews dataset (Glove Amazon).
We have demonstrated Glove Amazon is good for these models on the binary setting but can be harmful to them in the fine-grained setting.
Our experiments also show that a combination of both Glove Amazon and the standard Glove is more beneficial for CNN-Tree-LSTM compared to CNN-LSTM as 2-channel CNN-Tree-LSTM outperforms 2-channel CNN-LSTM on both binary and fine-grained setting.


