\section{Introduction}
In recent years, thanks to the dramatic growth of social media, customers' opinions are expressed in the highest speed and volume ever recorded in history.
With this amount of data, it is inefficient to read and analyze or even collect them manually. 
Sentiment analysis offers a way to collect and process public opinion automatically.
In a nutshell, sentiment analysis is to determine whether the opinion about a specific product, event, organization is positive or negative. 
It is also known as opinion mining due to the sentiment was derived from opinions of the speaker.

Formally, given document $d$, The main objective of sentiment analysis is to extract the following quintuple~\cite{liu2012sentiment}:
\[ ( e_{i}, a_{ij}, s_{ijkl}, h_{k}, t_{l} ) \]
Where:
\begin{itemize}
	\item $e_{i}$: entity i (entity extraction and categorization)
	\item $a_{ij}$: aspect j of entity i (entity extraction and categorization)
	\item $h_{k}$: holder k (opinion holder extraction and categorization)
	\item $t_{l}$: time l (time extraction and standardization)
	\item $s_{ijkl}$: opinion of holder k about aspect j of entity i at time l (aspect sentiment classification)
\end{itemize}
Sentence-level sentiment analysis is to determine whether a sentence expresses positive or negative sentiment. 
This level of analysis assumes that every sentence only contain one opinion toward an entity (e.g. a single movie)~\cite{liu2012sentiment}.

In this paper, we explored two ideas: ``Combining Convolution and Recursive Neural Networks'' (the main idea) and ``Transfer Learning From Large Review Dataset'' (the support idea).
%\begin{description}
%	\item[Combining Convolution and Recursive Neural Networks] Convolution (Section~\ref{sec:cnn}) and Recursive Neural Networks (Section~\ref{sec:recursive-nn}) have been proved to be effective network architects for sentence-level sentiment analysis.
%	Nevertheless, each of them has its own potential drawbacks (Section~\ref{sec:cnn-weak},~\ref{sec:recursive-nn-weak}).
%	For alleviating their weaknesses, we combined Convolution and Recursive Neural Networks into a new network architect (Section~\ref{sec:cnn-treelstm}) which is able to outperform both Convolution and Recursive Neural Networks (Section~\ref{sec:result}) on Stanford Sentiment Treebank (Section~\ref{sec:sst}).
%	This approach is closely related to the paper of Wang et al.~\cite{cnn-rnn} which investigate the combination Convolution and Recurrent Neural Networks.
%	\item[Transfer Learning From Large Review Dataset] One obstacle of solving sentence-level sentiment analysis is the lack of labeled data which potentially causes many drawbacks and one of them is over-fitting word embedding (Section~\ref{sec:word-weak}).
%	Since most opinions are expressed in form of  documents (i.e. multiple sentences), sentence-level labeled dataset required more work to produce.
%	Until now, the largest dataset for sentence-level sentiment analysis is Standford Sentiment Treebank which only contains 11,855 sentences.
%	This number is insignificant compared to Amazon Review dataset (Section~\ref{sec:amazon}) which has 83.68 million reviews.
%	We utilized Amazon Review dataset to train a new word embedding (Section~\ref{sec:glove-amazon}) which was named ``Glove Amazon''.
%	By replacing the standard Glove\footnote{Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download) publicly available at \url{https://nlp.stanford.edu/projects/glove/}} with Glove Amazon, many models are able to gain large improvements when evaluated on Stanford Sentiment Treebank.
%	We also demonstrated that a combination of Glove Amazon and standard Glove is better than each of the word embeddings (Section~\ref{sec:result}).
%\end{description}
\paragraph{Combining Convolution and Recursive Neural Networks}Convolution (Section~\ref{sec:cnn}) and Recursive Neural Networks (Section~\ref{sec:recursive-nn}) have been proved to be effective network architects for sentence-level sentiment analysis.
	Nevertheless, each of them has its own potential drawbacks (Section~\ref{sec:cnn-weak},~\ref{sec:recursive-nn-weak}).
	For alleviating their weaknesses, we combined Convolution and Recursive Neural Networks into a new network architect (Section~\ref{sec:cnn-treelstm}) which is able to outperform both Convolution and Recursive Neural Networks (Section~\ref{sec:result}) on Stanford Sentiment Treebank (Section~\ref{sec:sst}).
	This approach is closely related to the paper of Wang et al.~\cite{cnn-rnn} which investigate the combination Convolution and Recurrent Neural Networks.
\paragraph{Transfer Learning From Large Review Dataset} One obstacle of solving sentence-level sentiment analysis is the lack of labeled data which potentially causes many drawbacks and one of them is over-fitting word embedding (Section~\ref{sec:word-weak}).
	Since most opinions are expressed in form of  documents (i.e. multiple sentences), sentence-level labeled dataset required more work to produce.
	Until now, the largest dataset for sentence-level sentiment analysis is Standford Sentiment Treebank which only contains 11,855 sentences.
	This number is insignificant compared to Amazon Review dataset (Section~\ref{sec:amazon}) which has 83.68 million reviews.
	We utilized Amazon Review dataset to train a new word embedding (Section~\ref{sec:glove-amazon}) which was named ``Glove Amazon''.
	By replacing the standard Glove\footnote{Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download) publicly available at \url{https://nlp.stanford.edu/projects/glove/}} with Glove Amazon, many models are able to gain large improvements when evaluated on Stanford Sentiment Treebank.
	We also demonstrated that a combination of Glove Amazon and standard Glove is better than each of the word embeddings (Section~\ref{sec:result}).

